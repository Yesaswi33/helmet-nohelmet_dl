

https://github.com/user-attachments/assets/437321a0-2152-487a-8f2d-53e1e2318ff0




â€œI built a hybrid CNN model that combines ResNet50, EfficientNet, and MobileNet for helmet vs no-helmet detection, and deployed it using FastAPI.â€

Goal

Binary image classification:

with_helmet

without_helmet

Why hybrid?

Each backbone learns different types of visual features

Combining them improves generalization and robustness

2ï¸âƒ£ High-Level Architecture (Core Explanation)
ğŸ”¹ Backbone Networks Used
Model	Strength
ResNet50	Deep semantic features, strong gradient flow
EfficientNet	Optimal depthâ€“widthâ€“resolution scaling
MobileNet	Lightweight, fast, edge-friendly features
ğŸ”¹ Hybrid Design (Conceptual)
Input Image
   â†“
Shared Preprocessing (256Ã—256)
   â†“
ResNet50  â†’ Feature Vector
EfficientNet â†’ Feature Vector
MobileNet â†’ Feature Vector
   â†“
Feature Concatenation
   â†“
Fully Connected Layers
   â†“
Softmax Output (2 classes)


ğŸ“Œ Key idea:
Each model extracts complementary representations, then theyâ€™re fused.

3ï¸âƒ£ Mathematical Intuition (Important for Interviews)
ğŸ”¹ CNN Feature Extraction

Each backbone learns:

ğ‘“
ğ‘–
(
ğ‘¥
)
=
CNN
ğ‘–
(
ğ‘¥
)
f
i
	â€‹

(x)=CNN
i
	â€‹

(x)

where:

ğ‘¥
x = input image

ğ‘“
ğ‘–
f
i
	â€‹

 = feature vector from model 
ğ‘–
i

ğŸ”¹ Feature Fusion

Features are concatenated:

ğ¹
=
[
ğ‘“
ğ‘Ÿ
ğ‘’
ğ‘ 
ğ‘›
ğ‘’
ğ‘¡
â€…â€Š
âˆ£
âˆ£
â€…â€Š
ğ‘“
ğ‘’
ğ‘“
ğ‘“
ğ‘–
ğ‘
ğ‘–
ğ‘’
ğ‘›
ğ‘¡
ğ‘›
ğ‘’
ğ‘¡
â€…â€Š
âˆ£
âˆ£
â€…â€Š
ğ‘“
ğ‘š
ğ‘œ
ğ‘
ğ‘–
ğ‘™
ğ‘’
ğ‘›
ğ‘’
ğ‘¡
]
F=[f
resnet
	â€‹

âˆ£âˆ£f
efficientnet
	â€‹

âˆ£âˆ£f
mobilenet
	â€‹

]

This creates a richer representation space.

ğŸ”¹ Classification Layer

Final dense layer computes:

ğ‘§
=
ğ‘Š
ğ¹
+
ğ‘
z=WF+b

Softmax converts logits to probabilities:

ğ‘ƒ
(
ğ‘¦
=
ğ‘˜
)
=
ğ‘’
ğ‘§
ğ‘˜
âˆ‘
ğ‘—
ğ‘’
ğ‘§
ğ‘—
P(y=k)=
âˆ‘
j
	â€‹

e
z
j
	â€‹

e
z
k
	â€‹

	â€‹


Binary output:

Helmet

No Helmet

4ï¸âƒ£ Why Each Model Matters (Strong Interview Point)
ğŸ”¹ ResNet50 â€“ Deep Understanding

Uses skip connections

ğ‘¦
=
ğ¹
(
ğ‘¥
)
+
ğ‘¥
y=F(x)+x

Solves vanishing gradients

Captures global semantic cues like helmet shape

ğŸ”¹ EfficientNet â€“ Balanced Scaling

Scales depth, width, resolution together

Learns fine-grained textures

Efficient use of parameters

ğŸ”¹ MobileNet â€“ Speed & Edge Awareness

Uses depthwise separable convolutions

Standard Conv
=
ğ»
ğ‘Š
â‹…
ğ¶
ğ‘–
ğ‘›
â‹…
ğ¶
ğ‘œ
ğ‘¢
ğ‘¡
Standard Conv=HWâ‹…C
in
	â€‹

â‹…C
out
	â€‹

Depthwise Conv
=
ğ»
ğ‘Š
â‹…
ğ¶
ğ‘–
ğ‘›
Depthwise Conv=HWâ‹…C
in
	â€‹

Pointwise Conv
=
ğ¶
ğ‘–
ğ‘›
â‹…
ğ¶
ğ‘œ
ğ‘¢
ğ‘¡
Pointwise Conv=C
in
	â€‹

â‹…C
out
	â€‹


Captures lightweight local features

Makes model deployment-friendly

5ï¸âƒ£ Why Hybrid > Single Model (Must Say This)

âœ… Reduces model bias
âœ… Improves feature diversity
âœ… Better performance under:

Different lighting

Occlusions

Camera angles

â€œIf one backbone misses a cue, another compensates.â€

6ï¸âƒ£ Training Strategy (Even if Notebook is Lost)

You can confidently say:

Used transfer learning

Loaded pretrained ImageNet weights

Froze early layers initially

Fine-tuned later layers

Optimizer: Adam

ğœƒ
=
ğœƒ
âˆ’
ğ›¼
â‹…
âˆ‡
ğ¿
(
ğœƒ
)
Î¸=Î¸âˆ’Î±â‹…âˆ‡L(Î¸)

Loss: Categorical Cross-Entropy

ğ¿
=
âˆ’
âˆ‘
ğ‘¦
log
â¡
(
ğ‘¦
^
)
L=âˆ’âˆ‘ylog(
y
^
	â€‹

)
7ï¸âƒ£ Preprocessing Pipeline (Your FastAPI Code Matches This)

âœ” Resize to 256 Ã— 256
âœ” Normalize to [0,1]
âœ” Batch dimension added
âœ” TensorFlow decoding (framework-consistent)

This is correct and production-ready.

8ï¸âƒ£ Deployment Architecture (Very Important)
ğŸ”¹ FastAPI Inference Flow
Client â†’ Image Upload
       â†’ TensorFlow Preprocessing
       â†’ Hybrid Model Prediction
       â†’ Softmax Probability
       â†’ HTML Response

ğŸ”¹ Why FastAPI?

Async

Lightweight

Production-ready

Easy ML integration

9ï¸âƒ£ Confidence Score Explanation
confidence
=
max
â¡
(
softmax output
)
Ã—
100
confidence=max(softmax output)Ã—100

Shows model certainty, not just label.
